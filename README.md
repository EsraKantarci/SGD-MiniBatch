# SGD-MiniBatch
How to apply stochastic gradient descent or mini batch gradient descent to Neural Network without using machine learning libraries? Here is the recipe. And also, for the neural network implementation explanations, please see my older repositories.
